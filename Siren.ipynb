{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOlKf9fp2zP7DNcc4AlZwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SGeerthan/Emergency-Vehicle-Detection-and-Signal-Triggering/blob/feature%2Faudio-siren-detection/Siren.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUxqtzDYUL4n",
        "outputId": "10b11731-15a7-44b5-cd0d-634247647a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path where your dataset.zip is saved in Google Drive\n",
        "zip_path = \"/content/drive/MyDrive/dataset.zip\"\n",
        "extract_path = \"/content/siren-detector/data/raw\"\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"✅ Dataset extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VbrXTiJURf1",
        "outputId": "0191d34d-1b1f-4891-822b-824db2bf62f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset extracted to: /content/siren-detector/data/raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa tensorflow scikit-learn matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzhNNX1eUZXA",
        "outputId": "5a82644b-01cf-4d4a-f504-e4143f0bbe91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_PATH = \"/content/siren-detector/data/raw/dataset\" # Corrected path\n",
        "OUTPUT_PATH = \"/content/siren-detector/data/processed\"\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "def extract_features(file_path, n_mfcc=40, max_len=100):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file_path, sr=None)\n",
        "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
        "        if mfcc.shape[1] < max_len:\n",
        "            pad_width = max_len - mfcc.shape[1]\n",
        "            mfcc = np.pad(mfcc, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfcc = mfcc[:, :max_len]\n",
        "        return mfcc\n",
        "    except Exception as e:\n",
        "        print(\"Error extracting\", file_path, \":\", e)\n",
        "        return None\n",
        "\n",
        "X, y = [], []\n",
        "labels = [d for d in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, d))] # Get subdirectories as labels\n",
        "label_to_idx = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "for label in labels:\n",
        "    folder = os.path.join(DATA_PATH, label)\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith(\".wav\"):\n",
        "            path = os.path.join(folder, file)\n",
        "            features = extract_features(path)\n",
        "            if features is not None:\n",
        "                X.append(features)\n",
        "                y.append(label_to_idx[label])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ Features extracted:\", X.shape, \"Labels:\", y.shape)\n",
        "\n",
        "# Save processed data\n",
        "np.save(os.path.join(OUTPUT_PATH, \"X.npy\"), X)\n",
        "np.save(os.path.join(OUTPUT_PATH, \"y.npy\"), y)\n",
        "np.save(os.path.join(OUTPUT_PATH, \"labels.npy\"), labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HOQhJX9UgHW",
        "outputId": "dbfd5d58-9e76-4215-c360-bad29b0ee2b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Features extracted: (600, 40, 100) Labels: (600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "DATA_PATH = \"/content/siren-detector/data/raw/dataset\"\n",
        "\n",
        "for label in os.listdir(DATA_PATH):\n",
        "    folder = os.path.join(DATA_PATH, label)\n",
        "    if os.path.isdir(folder):\n",
        "        files = [f for f in os.listdir(folder) if f.endswith(\".wav\")]\n",
        "        print(label, \"has\", len(files), \"files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn6ZxD1jVBVY",
        "outputId": "4f9c88c8-de67-45c0-de47-d2c11fce5905"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "firetruck has 200 files\n",
            "normal has 200 files\n",
            "ambulance has 200 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5d111d3c",
        "outputId": "fcb3b995-1dd8-4923-c63b-cf36c539c504"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Load processed data\n",
        "X = np.load(\"/content/siren-detector/data/processed/X.npy\")\n",
        "y = np.load(\"/content/siren-detector/data/processed/y.npy\")\n",
        "labels = np.load(\"/content/siren-detector/data/processed/labels.npy\", allow_pickle=True)\n",
        "\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Reshape for CNN: (samples, height, width, channels)\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "# One-hot encode labels\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"✅ Training samples:\", X_train.shape[0], \"Test samples:\", X_test.shape[0])\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=X.shape[1:]),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=30,\n",
        "                    batch_size=16)\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = \"/content/siren-detector/models\"\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "model.save(os.path.join(model_save_path, \"best_model.keras\"))\n",
        "print(\"✅ Model saved at\", os.path.join(model_save_path, \"best_model.keras\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training samples: 480 Test samples: 120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11776\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,507,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11776</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,507,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,527,043\u001b[0m (5.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,527,043</span> (5.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,526,851\u001b[0m (5.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,526,851</span> (5.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 190ms/step - accuracy: 0.6531 - loss: 3.9781 - val_accuracy: 0.4583 - val_loss: 6.1685\n",
            "Epoch 2/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 123ms/step - accuracy: 0.8937 - loss: 0.2968 - val_accuracy: 0.4667 - val_loss: 2.3829\n",
            "Epoch 3/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.8963 - loss: 0.2204 - val_accuracy: 0.6167 - val_loss: 1.1710\n",
            "Epoch 4/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - accuracy: 0.9611 - loss: 0.1154 - val_accuracy: 0.8167 - val_loss: 0.3559\n",
            "Epoch 5/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - accuracy: 0.9421 - loss: 0.1615 - val_accuracy: 0.9083 - val_loss: 0.2304\n",
            "Epoch 6/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.9438 - loss: 0.1431 - val_accuracy: 0.9333 - val_loss: 0.1726\n",
            "Epoch 7/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.9628 - loss: 0.0927 - val_accuracy: 0.9250 - val_loss: 0.2002\n",
            "Epoch 8/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - accuracy: 0.9627 - loss: 0.1014 - val_accuracy: 0.9417 - val_loss: 0.1469\n",
            "Epoch 9/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.9581 - loss: 0.1122 - val_accuracy: 0.9417 - val_loss: 0.1292\n",
            "Epoch 10/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.9809 - loss: 0.0518 - val_accuracy: 0.9583 - val_loss: 0.1094\n",
            "Epoch 11/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 177ms/step - accuracy: 0.9858 - loss: 0.0406 - val_accuracy: 0.9667 - val_loss: 0.1265\n",
            "Epoch 12/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.9747 - loss: 0.0614 - val_accuracy: 0.9500 - val_loss: 0.1030\n",
            "Epoch 13/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - accuracy: 0.9843 - loss: 0.0353 - val_accuracy: 0.9667 - val_loss: 0.1457\n",
            "Epoch 14/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.9941 - loss: 0.0195 - val_accuracy: 0.9583 - val_loss: 0.1110\n",
            "Epoch 15/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.9967 - loss: 0.0208 - val_accuracy: 0.9667 - val_loss: 0.1350\n",
            "Epoch 16/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 180ms/step - accuracy: 0.9941 - loss: 0.0229 - val_accuracy: 0.9583 - val_loss: 0.1056\n",
            "Epoch 17/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.9996 - loss: 0.0101 - val_accuracy: 0.9667 - val_loss: 0.1563\n",
            "Epoch 18/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.9898 - loss: 0.0304 - val_accuracy: 0.9583 - val_loss: 0.2363\n",
            "Epoch 19/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 146ms/step - accuracy: 0.9933 - loss: 0.0236 - val_accuracy: 0.9417 - val_loss: 0.1921\n",
            "Epoch 20/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - accuracy: 0.9585 - loss: 0.0981 - val_accuracy: 0.9667 - val_loss: 0.2182\n",
            "Epoch 21/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - accuracy: 0.9740 - loss: 0.1415 - val_accuracy: 0.9583 - val_loss: 0.2000\n",
            "Epoch 22/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - accuracy: 0.9895 - loss: 0.0213 - val_accuracy: 0.9667 - val_loss: 0.2246\n",
            "Epoch 23/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.9966 - loss: 0.0167 - val_accuracy: 0.9750 - val_loss: 0.1991\n",
            "Epoch 24/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - accuracy: 0.9564 - loss: 0.2271 - val_accuracy: 0.9750 - val_loss: 0.2008\n",
            "Epoch 25/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.9767 - loss: 0.0531 - val_accuracy: 0.9500 - val_loss: 0.3480\n",
            "Epoch 26/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.9784 - loss: 0.1371 - val_accuracy: 0.9667 - val_loss: 0.1130\n",
            "Epoch 27/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 174ms/step - accuracy: 0.9872 - loss: 0.0654 - val_accuracy: 0.9500 - val_loss: 0.1886\n",
            "Epoch 28/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.9833 - loss: 0.0235 - val_accuracy: 0.9583 - val_loss: 0.1401\n",
            "Epoch 29/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.9913 - loss: 0.0326 - val_accuracy: 0.9500 - val_loss: 0.1310\n",
            "Epoch 30/30\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 171ms/step - accuracy: 0.9938 - loss: 0.0163 - val_accuracy: 0.9583 - val_loss: 0.1373\n",
            "✅ Model saved at /content/siren-detector/models/best_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load trained model\n",
        "MODEL_PATH = \"/content/siren-detector/models/best_model.keras\"\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "# Define class names (must match your dataset folder names order)\n",
        "class_names = [\"ambulance\", \"firetruck\", \"normal\"]\n",
        "\n",
        "# Function to preprocess and predict\n",
        "def predict_audio(file_path):\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(file_path, sr=22050)\n",
        "\n",
        "    # Extract MFCC features\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "    mfcc_scaled = np.mean(mfcc.T, axis=0)\n",
        "\n",
        "    # Reshape for model\n",
        "    mfcc_scaled = mfcc_scaled.reshape(1, -1)\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(mfcc_scaled)\n",
        "    predicted_class = class_names[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    print(f\"Prediction: {predicted_class} ({confidence*100:.2f}%)\")\n",
        "    return predicted_class, confidence\n"
      ],
      "metadata": {
        "id": "__1FnhUqYkol"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a286be5"
      },
      "source": [
        "# Task\n",
        "Evaluate the trained model's performance by loading the saved model and test data. Predict on the test data (`X_test`), then calculate and display a classification report (including accuracy, precision, recall, and F1-score) and a confusion matrix to summarize the model's effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03cc1f18"
      },
      "source": [
        "## Load Model and Data\n",
        "\n",
        "### Subtask:\n",
        "Load the trained Keras model and the preprocessed test data (X_test, y_test) along with the class labels that were saved during the training phase.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f989f34"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the preprocessed test data (X_test, y_test) and class labels using numpy, and the trained Keras model using TensorFlow.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935ae624",
        "outputId": "82c2232d-bad1-4a43-e292-73d7d229398f"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Load trained model\n",
        "MODEL_PATH = \"/content/siren-detector/models/best_model.keras\"\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "# X_test and y_test are already available in the kernel from previous steps\n",
        "# No need to load them if they haven't been explicitly saved to disk.\n",
        "# If they were intended to be loaded from disk, the saving step would be needed earlier.\n",
        "\n",
        "# Load class labels (this file was saved previously)\n",
        "labels = np.load(\"/content/siren-detector/data/processed/labels.npy\", allow_pickle=True)\n",
        "\n",
        "print(\"✅ Model, X_test, y_test (from memory), and labels loaded successfully.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model, X_test, y_test (from memory), and labels loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0e5e3611",
        "outputId": "727b7dc3-2f83-4d52-c398-2800de27f3be"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "model_path = \"/content/siren-detector/models/best_model.keras\"\n",
        "if os.path.exists(model_path):\n",
        "    files.download(model_path)\n",
        "    print(f\"✅ Model '{os.path.basename(model_path)}' downloaded successfully.\")\n",
        "else:\n",
        "    print(f\"❌ Model not found at {model_path}. Please ensure the model was trained and saved correctly.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d23c561d-53ca-4efd-ab73-ae742e0d5598\", \"best_model.keras\", 18379136)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model 'best_model.keras' downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17103f4"
      },
      "source": [
        "## Predict on Test Data\n",
        "\n",
        "### Subtask:\n",
        "Use the loaded model to make predictions on the `X_test` dataset. This will give us the model's output probabilities for each class for the test samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "135ca808"
      },
      "source": [
        "**Reasoning**:\n",
        "To make predictions, I will use the `predict` method of the loaded Keras model on the `X_test` data and store the output probabilities in `y_pred_probs`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "193b5226",
        "outputId": "3b97dcb2-3c39-4c32-f8d5-dc1e306e9cd3"
      },
      "source": [
        "y_pred_probs = model.predict(X_test)\n",
        "print(\"✅ Predictions made successfully.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step\n",
            "✅ Predictions made successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dde6213"
      },
      "source": [
        "**Reasoning**:\n",
        "To calculate metrics like precision, recall, F1-score, and display a confusion matrix, it is necessary to convert the predicted probabilities (`y_pred_probs`) into concrete class predictions (0 or 1 for each class). This involves identifying the class with the highest probability for each sample.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd118c95",
        "outputId": "fd34dedb-10e4-49bd-d8e8-1e575fc07481"
      },
      "source": [
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "print(\"✅ Predicted classes derived successfully.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predicted classes derived successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588f3db1"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that we have the predicted classes (`y_pred_classes`), we need to convert the one-hot encoded `y_test` into integer labels to properly evaluate the model's performance using classification metrics like precision, recall, and F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec04e311",
        "outputId": "e2dffe03-7f9d-4b71-e999-0733d62ff505"
      },
      "source": [
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "print(\"✅ True classes derived successfully.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ True classes derived successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7e16407"
      },
      "source": [
        "**Reasoning**:\n",
        "To evaluate the model's performance comprehensively, I will generate a classification report using `y_true_classes` and `y_pred_classes`, which will include precision, recall, f1-score, and support for each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "792f649c",
        "outputId": "7583d35c-1a68-4c44-c2d2-4f5ad7dbcb31"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=labels))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   firetruck       0.97      0.90      0.94        40\n",
            "      normal       1.00      1.00      1.00        40\n",
            "   ambulance       0.91      0.97      0.94        40\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0de62026"
      },
      "source": [
        "**Reasoning**:\n",
        "To visually represent the model's performance and identify specific misclassifications, I will generate and display a confusion matrix using `seaborn.heatmap`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "b9cef72f",
        "outputId": "46097baf-6f37-47fb-f77d-045832832565"
      },
      "source": [
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "print(\"✅ Confusion matrix displayed successfully.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Confusion matrix displayed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "291b2a87"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the model's performance based on the calculated metrics and the confusion matrix, highlighting key insights into its accuracy, precision, and F1-score for each class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62690511"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The model's performance, as evaluated by the calculated metrics and the confusion matrix, demonstrates strong capabilities in classifying sound events into \"firetruck\", \"normal\", and \"ambulance\" categories.\n",
        "\n",
        "*   **Overall Accuracy:** The model achieved an overall accuracy of 0.96.\n",
        "*   **\"Normal\" Class:** The model performed exceptionally well for the \"normal\" class, achieving a perfect precision, recall, and F1-score of 1.00, indicating no misclassifications for this category.\n",
        "*   **\"Firetruck\" Class:** For \"firetruck\" sounds, the model showed strong performance with a precision of 0.97, recall of 0.90, and an F1-score of 0.94. This indicates that when the model predicts \"firetruck\", it's usually correct, but it missed identifying 10% of actual \"firetruck\" sounds.\n",
        "*   **\"Ambulance\" Class:** The \"ambulance\" class also performed well with a precision of 0.91, recall of 0.97, and an F1-score of 0.94. This suggests the model is very good at identifying actual \"ambulance\" sounds, but sometimes misclassifies other sounds as \"ambulance\".\n",
        "*   **Confusion Matrix:** The confusion matrix visually supports these findings, clearly showing the number of correct and incorrect predictions for each class, with minimal confusion observed between the classes, particularly distinguishing \"normal\" from the others.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The trained Keras model and class labels were successfully loaded. `X_test` and `y_test` were utilized directly from memory where they were available from previous processing steps.\n",
        "*   The model successfully generated predictions on the test dataset, and these probabilities were converted into discrete class predictions.\n",
        "*   A classification report revealed an overall model accuracy of 0.96.\n",
        "*   The \"normal\" class achieved perfect scores (precision 1.00, recall 1.00, F1-score 1.00).\n",
        "*   The \"firetruck\" class showed high precision (0.97) and F1-score (0.94), with a recall of 0.90.\n",
        "*   The \"ambulance\" class demonstrated high recall (0.97) and F1-score (0.94), with a precision of 0.91.\n",
        "*   A confusion matrix was generated and visualized, confirming the strong performance and providing a clear breakdown of correct and incorrect classifications across the three classes.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The model exhibits excellent performance, particularly in identifying \"normal\" sounds and generally high accuracy across all classes, making it suitable for deployment in scenarios where distinguishing siren sounds is critical.\n",
        "*   Further investigation into the misclassifications between \"firetruck\" and \"ambulance\" sounds could involve analyzing specific instances of misclassified audio, potentially leading to improvements in feature engineering or model architecture to enhance their distinctiveness.\n"
      ]
    }
  ]
}